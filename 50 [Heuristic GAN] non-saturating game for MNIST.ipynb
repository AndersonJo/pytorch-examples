{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import dataloader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = MNIST('./data', train=True, download=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(), # ToTensor does min-max normalization. \n",
    "]), )\n",
    "\n",
    "test = MNIST('./data', train=False, download=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(), # ToTensor does min-max normalization. \n",
    "    \n",
    "]), )\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader_args = dict(shuffle=True, batch_size=BATCH_SIZE ,num_workers=1, pin_memory=True)\n",
    "train_loader = dataloader.DataLoader(train, **dataloader_args)\n",
    "test_loader = dataloader.DataLoader(test, **dataloader_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Discriminator\n",
    "\n",
    "### Discriminator\n",
    "\n",
    "* $ x_i \\sim P_{\\rm data} $ (즉 true data distribution) 에서 왔다면 1\n",
    "* $ x_i = G(z) $ 이때 $ z \\sim p_{\\rm generator} $ (generators' distribution)에서 왔다면 0\n",
    "\n",
    "즉 Discriminator는 \"이 사진이 진짜냐? (가짜가 아니고)\" 라고 질문하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator (\n",
      "  (fc1): Linear (784 -> 384)\n",
      "  (fc2): Linear (384 -> 8)\n",
      "  (fc3): Linear (8 -> 1)\n",
      "  (bc1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (bc2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(784, 384)\n",
    "        self.fc2 = nn.Linear(384, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        \n",
    "        self.bc1 = nn.BatchNorm1d(384)\n",
    "        self.bc2 = nn.BatchNorm1d(8)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = x.view((-1, 784))\n",
    "        h = self.fc1(x)\n",
    "        h = self.bc1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        \n",
    "\n",
    "        h = self.fc2(h)\n",
    "        h = self.bc2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        \n",
    "        h = self.fc3(h)\n",
    "        out = F.sigmoid(h)\n",
    "        return out\n",
    "\n",
    "D = Discriminator()\n",
    "print(D.cuda()) # CUDA!\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator (\n",
      "  (fc1): Linear (100 -> 196)\n",
      "  (fc2): Linear (196 -> 289)\n",
      "  (fc3): Linear (289 -> 361)\n",
      "  (fc4): Linear (361 -> 400)\n",
      "  (fc5): Linear (400 -> 512)\n",
      "  (fc6): Linear (512 -> 625)\n",
      "  (fc7): Linear (625 -> 784)\n",
      "  (fc8): Linear (784 -> 784)\n",
      "  (bc1): BatchNorm1d(196, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (bc2): BatchNorm1d(289, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (bc3): BatchNorm1d(361, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (bc4): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (bc5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (bc6): BatchNorm1d(625, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (bc7): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(100, 196)\n",
    "        self.fc2 = nn.Linear(196, 289)\n",
    "        self.fc3 = nn.Linear(289, 361)\n",
    "        self.fc4 = nn.Linear(361, 400)\n",
    "        self.fc5 = nn.Linear(400, 512)\n",
    "        self.fc6 = nn.Linear(512, 625)\n",
    "        self.fc7 = nn.Linear(625, 784)\n",
    "        self.fc8 = nn.Linear(784, 784)\n",
    "        \n",
    "        self.bc1 = nn.BatchNorm1d(196)\n",
    "        self.bc2 = nn.BatchNorm1d(289)\n",
    "        self.bc3 = nn.BatchNorm1d(361)\n",
    "        self.bc4 = nn.BatchNorm1d(400)\n",
    "        self.bc5 = nn.BatchNorm1d(512)\n",
    "        self.bc6 = nn.BatchNorm1d(625)\n",
    "        self.bc7 = nn.BatchNorm1d(784)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.fc1(x)\n",
    "        h = self.bc1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        \n",
    "        h = self.fc2(h)\n",
    "        h = self.bc2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        \n",
    "        h = self.fc3(h)\n",
    "        h = self.bc3(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        \n",
    "        h = self.fc4(h)\n",
    "        h = self.bc4(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = F.dropout(h, p=0.4, training=self.training)\n",
    "        \n",
    "        h = self.fc5(h)\n",
    "        h = self.bc5(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = F.dropout(h, p=0.4, training=self.training)\n",
    "        \n",
    "        h = self.fc6(h)\n",
    "        h = self.bc6(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = F.dropout(h, p=0.4, training=self.training)\n",
    "        \n",
    "        h = self.fc7(h)\n",
    "        h = self.bc7(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = F.dropout(h, p=0.4, training=self.training)\n",
    "        \n",
    "        h = self.fc8(h)\n",
    "        out = F.sigmoid(h)\n",
    "        return out\n",
    "\n",
    "G = Generator()\n",
    "print(G.cuda())\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dot(var):\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if isinstance(var, Variable):\n",
    "                value = '('+(', ').join(['%d'% v for v in var.size()])+')'\n",
    "                dot.node(str(id(var)), str(value), fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'previous_functions'):\n",
    "                for u in var.previous_functions:\n",
    "                    dot.edge(str(id(u[0])), str(id(var)))\n",
    "                    add_nodes(u[0])\n",
    "    add_nodes(var.creator)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"252pt\" height=\"200pt\"\n",
       " viewBox=\"0.00 0.00 251.50 200.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 196)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-196 247.5,-196 247.5,4 -4,4\"/>\n",
       "<!-- 140286809045256 -->\n",
       "<g id=\"node1\" class=\"node\"><title>140286809045256</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"172.5,-21 116.5,-21 116.5,-0 172.5,-0 172.5,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"144.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\">Sigmoid</text>\n",
       "</g>\n",
       "<!-- 140286809044360 -->\n",
       "<g id=\"node2\" class=\"node\"><title>140286809044360</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"171.5,-78 117.5,-78 117.5,-57 171.5,-57 171.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"144.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">Linear</text>\n",
       "</g>\n",
       "<!-- 140286809044360&#45;&gt;140286809045256 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>140286809044360&#45;&gt;140286809045256</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M144.5,-56.9197C144.5,-49.9083 144.5,-40.1442 144.5,-31.4652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"148,-31.3408 144.5,-21.3408 141,-31.3409 148,-31.3408\"/>\n",
       "</g>\n",
       "<!-- 140286809044136 -->\n",
       "<g id=\"node3\" class=\"node\"><title>140286809044136</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"99,-135 22,-135 22,-114 99,-114 99,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"60.5\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\">LeakyReLU</text>\n",
       "</g>\n",
       "<!-- 140286809044136&#45;&gt;140286809044360 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>140286809044136&#45;&gt;140286809044360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M75.1317,-113.92C87.8216,-105.611 106.415,-93.4363 121.159,-83.7828\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"123.305,-86.5611 129.754,-78.155 119.471,-80.7048 123.305,-86.5611\"/>\n",
       "</g>\n",
       "<!-- 140286809142944 -->\n",
       "<g id=\"node4\" class=\"node\"><title>140286809142944</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"121,-192 7.10543e-15,-192 7.10543e-15,-171 121,-171 121,-192\"/>\n",
       "<text text-anchor=\"middle\" x=\"60.5\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\">BatchNormBackward</text>\n",
       "</g>\n",
       "<!-- 140286809142944&#45;&gt;140286809044136 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>140286809142944&#45;&gt;140286809044136</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M60.5,-170.92C60.5,-163.908 60.5,-154.144 60.5,-145.465\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"64.0001,-145.341 60.5,-135.341 57.0001,-145.341 64.0001,-145.341\"/>\n",
       "</g>\n",
       "<!-- 140286808903352 -->\n",
       "<g id=\"node5\" class=\"node\"><title>140286808903352</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"171.5,-135 117.5,-135 117.5,-114 171.5,-114 171.5,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"144.5\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\">(1, 8)</text>\n",
       "</g>\n",
       "<!-- 140286808903352&#45;&gt;140286809044360 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>140286808903352&#45;&gt;140286809044360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M144.5,-113.92C144.5,-106.908 144.5,-97.1442 144.5,-88.4652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"148,-88.3408 144.5,-78.3408 141,-88.3409 148,-88.3408\"/>\n",
       "</g>\n",
       "<!-- 140286809055568 -->\n",
       "<g id=\"node6\" class=\"node\"><title>140286809055568</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"243.5,-135 189.5,-135 189.5,-114 243.5,-114 243.5,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\">(1)</text>\n",
       "</g>\n",
       "<!-- 140286809055568&#45;&gt;140286809044360 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>140286809055568&#45;&gt;140286809044360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M203.959,-113.92C193.352,-105.818 177.934,-94.0399 165.456,-84.5082\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167.454,-81.6299 157.383,-78.3408 163.205,-87.1926 167.454,-81.6299\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f97712cd198>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_image = train[0][0].cuda()\n",
    "real_image = Variable(real_image)\n",
    "make_dot(D(real_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"253pt\" height=\"314pt\"\n",
       " viewBox=\"0.00 0.00 252.50 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-310 248.5,-310 248.5,4 -4,4\"/>\n",
       "<!-- 140286640385160 -->\n",
       "<g id=\"node1\" class=\"node\"><title>140286640385160</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"166.5,-21 112.5,-21 112.5,-0 166.5,-0 166.5,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\">View</text>\n",
       "</g>\n",
       "<!-- 140286640384936 -->\n",
       "<g id=\"node2\" class=\"node\"><title>140286640384936</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"167.5,-78 111.5,-78 111.5,-57 167.5,-57 167.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">Sigmoid</text>\n",
       "</g>\n",
       "<!-- 140286640384936&#45;&gt;140286640385160 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>140286640384936&#45;&gt;140286640385160</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M139.5,-56.9197C139.5,-49.9083 139.5,-40.1442 139.5,-31.4652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"143,-31.3408 139.5,-21.3408 136,-31.3409 143,-31.3408\"/>\n",
       "</g>\n",
       "<!-- 140286640384712 -->\n",
       "<g id=\"node3\" class=\"node\"><title>140286640384712</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"166.5,-135 112.5,-135 112.5,-114 166.5,-114 166.5,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.5\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\">Linear</text>\n",
       "</g>\n",
       "<!-- 140286640384712&#45;&gt;140286640384936 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>140286640384712&#45;&gt;140286640384936</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M139.5,-113.92C139.5,-106.908 139.5,-97.1442 139.5,-88.4652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"143,-88.3408 139.5,-78.3408 136,-88.3409 143,-88.3408\"/>\n",
       "</g>\n",
       "<!-- 140286640384488 -->\n",
       "<g id=\"node4\" class=\"node\"><title>140286640384488</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"88.5,-192 32.5,-192 32.5,-171 88.5,-171 88.5,-192\"/>\n",
       "<text text-anchor=\"middle\" x=\"60.5\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\">Dropout</text>\n",
       "</g>\n",
       "<!-- 140286640384488&#45;&gt;140286640384712 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>140286640384488&#45;&gt;140286640384712</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M74.2607,-170.92C86.0827,-162.689 103.353,-150.666 117.155,-141.057\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.425,-143.741 125.632,-135.155 115.425,-137.996 119.425,-143.741\"/>\n",
       "</g>\n",
       "<!-- 140286640384264 -->\n",
       "<g id=\"node5\" class=\"node\"><title>140286640384264</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"99,-249 22,-249 22,-228 99,-228 99,-249\"/>\n",
       "<text text-anchor=\"middle\" x=\"60.5\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\">LeakyReLU</text>\n",
       "</g>\n",
       "<!-- 140286640384264&#45;&gt;140286640384488 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>140286640384264&#45;&gt;140286640384488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M60.5,-227.92C60.5,-220.908 60.5,-211.144 60.5,-202.465\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"64.0001,-202.341 60.5,-192.341 57.0001,-202.341 64.0001,-202.341\"/>\n",
       "</g>\n",
       "<!-- 140286809145184 -->\n",
       "<g id=\"node6\" class=\"node\"><title>140286809145184</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"121,-306 7.10543e-15,-306 7.10543e-15,-285 121,-285 121,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"60.5\" y=\"-292.4\" font-family=\"Times,serif\" font-size=\"12.00\">BatchNormBackward</text>\n",
       "</g>\n",
       "<!-- 140286809145184&#45;&gt;140286640384264 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>140286809145184&#45;&gt;140286640384264</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M60.5,-284.92C60.5,-277.908 60.5,-268.144 60.5,-259.465\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"64.0001,-259.341 60.5,-249.341 57.0001,-259.341 64.0001,-259.341\"/>\n",
       "</g>\n",
       "<!-- 140286809058384 -->\n",
       "<g id=\"node7\" class=\"node\"><title>140286809058384</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"172.5,-192 106.5,-192 106.5,-171 172.5,-171 172.5,-192\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.5\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\">(784, 784)</text>\n",
       "</g>\n",
       "<!-- 140286809058384&#45;&gt;140286640384712 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>140286809058384&#45;&gt;140286640384712</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M139.5,-170.92C139.5,-163.908 139.5,-154.144 139.5,-145.465\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"143,-145.341 139.5,-135.341 136,-145.341 143,-145.341\"/>\n",
       "</g>\n",
       "<!-- 140286809058472 -->\n",
       "<g id=\"node8\" class=\"node\"><title>140286809058472</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"244.5,-192 190.5,-192 190.5,-171 244.5,-171 244.5,-192\"/>\n",
       "<text text-anchor=\"middle\" x=\"217.5\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\">(784)</text>\n",
       "</g>\n",
       "<!-- 140286809058472&#45;&gt;140286640384712 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>140286809058472&#45;&gt;140286640384712</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M203.913,-170.92C192.241,-162.689 175.19,-150.666 161.562,-141.057\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"163.382,-138.057 153.193,-135.155 159.348,-143.778 163.382,-138.057\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f97712cd208>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_distributions = Variable(torch.randn((BATCH_SIZE, 100)).cuda())\n",
    "images = G(fake_distributions).view((-1, 28, 28))\n",
    "make_dot(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train\n",
    "\n",
    "* $ 1 $ : real images\n",
    "* $ 0 $ : fake images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "N_EPOCH = 1000\n",
    "\n",
    "real_y = Variable(torch.ones((BATCH_SIZE, 1)).cuda())\n",
    "fake_y = Variable(torch.zeros((BATCH_SIZE, 1)).cuda())\n",
    "loss_f = nn.BCELoss()\n",
    "\n",
    "d_real_losses = list()\n",
    "d_fake_losses = list()\n",
    "d_losses = list()\n",
    "g_losses = list()\n",
    "divergences = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000] divergence: 0.8926   D: 0.117    D_real: 0.09563  D_fake: 0.117    G:2.247   \n",
      "[2/1000] divergence: 0.9665   D: 0.03533  D_real: 0.02758  D_fake: 0.03533  G:3.479   \n",
      "[3/1000] divergence: 0.9602   D: 0.0435   D_real: 0.04225  D_fake: 0.0435   G:3.814   \n",
      "[4/1000] divergence: 0.969    D: 0.03221  D_real: 0.01497  D_fake: 0.03221  G:3.601   \n",
      "[5/1000] divergence: 0.9852   D: 0.01506  D_real: 0.007391 D_fake: 0.01506  G:4.307   "
     ]
    }
   ],
   "source": [
    "# Train Discriminator with Generator not being trained\n",
    "# 먼저 Discriminator를 학습시킵니다.\n",
    "# 이때 real image와 fake이미지 두개의 데이터를 사용하여 학습합니다. \n",
    "# Discriminator를 학습시킬때는 Generator는 학습시키면 안됩니다.\n",
    "for epoch in range(N_EPOCH):\n",
    "    for step, (real_images, _) in enumerate(train_loader):\n",
    "        # Samples\n",
    "        real_images = Variable(real_images.cuda())\n",
    "        z = Variable(torch.randn((BATCH_SIZE, 100)).cuda())\n",
    "                \n",
    "        ###############################################\n",
    "        # Train D (But do not train G)\n",
    "        ###############################################\n",
    "        # Init D\n",
    "        d_optimizer.zero_grad()\n",
    "        \n",
    "        # Calculate the loss with real images\n",
    "        y_real_pred = D(real_images)\n",
    "        d_real_loss = loss_f(y_real_pred, real_y)\n",
    "#         d_real_loss.backward()\n",
    "#         d_optimizer.step()\n",
    "        \n",
    "        # Calculate the loss with fake images\n",
    "        fake_distributions = Variable(torch.randn((BATCH_SIZE, 100)).cuda())\n",
    "        fake_images = G(fake_distributions).detach()\n",
    "        y_fake_pred = D(fake_images)\n",
    "        d_fake_loss = loss_f(y_fake_pred, fake_y)\n",
    "#         d_fake_loss.backward()\n",
    "#         d_optimizer.step()\n",
    "        \n",
    "        # Update D with G not being updated        \n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        ###############################################\n",
    "        # Train G with fake images but do not train G\n",
    "        ###############################################\n",
    "        g_optimizer.zero_grad()\n",
    "        \n",
    "        fake_distributions = Variable(torch.randn((BATCH_SIZE, 100)).cuda())\n",
    "        fake_images = G(fake_distributions)\n",
    "        y_pred = D(fake_images)\n",
    "        g_loss = loss_f(y_pred, real_y)\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        ###############################################\n",
    "        # Visualization\n",
    "        ###############################################\n",
    "        d_real_losses.append(d_real_loss.data[0])\n",
    "        d_fake_losses.append(d_fake_loss.data[0])\n",
    "        d_losses.append(d_loss.data[0])\n",
    "        g_losses.append(g_loss.data.cpu().numpy()[0])\n",
    "    \n",
    "        divergences.append(torch.mean(y_real_pred/(y_real_pred+y_fake_pred)).data[0])\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            print(f'\\r[{epoch+1}/{N_EPOCH}]',\n",
    "                  # '{:.4}'.format(torch.mean(params[0]).data[0]),\n",
    "                  'divergence: {:<8.4}'.format(np.mean(divergences[-100:])),\n",
    "                  'D: {:<8.4}'.format(np.mean(d_fake_losses[-100:])), \n",
    "                  'D_real: {:<8.4}'.format(np.mean(d_real_losses[-100:])),\n",
    "                  'D_fake: {:<8.4}'.format(np.mean(d_fake_losses[-100:])), \n",
    "                  'G:{:<8.4}'.format(np.mean(g_losses[-100:])), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loss Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def smooth(x,window_len=100,window='hanning'):\n",
    "    x = np.array(x)\n",
    "    \n",
    "    if x.ndim != 1:\n",
    "        raise ValueError(\"smooth only accepts 1 dimension arrays.\")\n",
    "\n",
    "    if x.size < window_len:\n",
    "        raise ValueError(\"Input vector needs to be bigger than window size.\")\n",
    "\n",
    "    if window_len<3:\n",
    "        return x\n",
    "\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise ValueError(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "\n",
    "    s=numpy.r_[x[window_len-1:0:-1],x,x[-1:-window_len:-1]]\n",
    "    \n",
    "    if window == 'flat': #moving average\n",
    "        w=numpy.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('numpy.'+window+'(window_len)')\n",
    "\n",
    "    y=numpy.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "figsize(16, 6)\n",
    "plot(smooth(d_real_losses), label='D(x) Loss')\n",
    "plot(smooth(d_fake_losses), label='D(G(z)) Loss')\n",
    "plot(smooth(g_losses), label='G(z) loss')\n",
    "plot(smooth(divergences), label='divergences')\n",
    "\n",
    "grid()\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot(d_real_losses, label='D(x) Loss')\n",
    "plot(d_fake_losses, label='D(G(z)) Loss')\n",
    "plot(g_losses, label='G(z) loss')\n",
    "plot(divergences, label='divergences')\n",
    "\n",
    "yscale('log')\n",
    "grid()\n",
    "legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluate\n",
    "\n",
    "## Evaluate Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fake_distributions = Variable(torch.randn((BATCH_SIZE, 100)).cuda())\n",
    "images = G(fake_distributions).view((-1, 28, 28)).data.cpu().numpy()\n",
    "\n",
    "images[0]\n",
    "imshow(images[0], cmap=cm.gray_r)\n",
    "\n",
    "fig, subplots = pylab.subplots(4, 7) # subplots(y축, x축 갯수)\n",
    "\n",
    "idx = 0\n",
    "for _subs in subplots:\n",
    "    for subplot in _subs:\n",
    "        d = images[idx]\n",
    "        subplot.get_xaxis().set_visible(False)\n",
    "        subplot.get_yaxis().set_visible(False)\n",
    "        subplot.imshow(d, cmap=cm.gray_r)\n",
    "        idx += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluate Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_test = test_loader.dataset.test_data.size()[0]\n",
    "y_test_real_labels = np.ones((n_test, 1))\n",
    "y_test_fake_labels = np.zeros((n_test, 1))\n",
    "\n",
    "# Predict Real Images\n",
    "test_data = Variable(test_loader.dataset.test_data.cuda().type_as(torch.cuda.FloatTensor()))\n",
    "y_test_real_pred = D(test_data)\n",
    "\n",
    "\n",
    "# Predict Fake Images\n",
    "fake_distributions = Variable(torch.randn((n_test, 100)).cuda())\n",
    "fake_images = G(fake_distributions).detach()\n",
    "y_test_fake_pred = D(fake_images)\n",
    "\n",
    "# Evaluate\n",
    "y_test_real_pred = torch.round(y_test_real_pred).data.cpu().numpy()\n",
    "y_test_fake_pred = torch.round(y_test_fake_pred).data.cpu().numpy()\n",
    "\n",
    "print('Discriminator Real Image Accuracy:', accuracy_score(y_test_real_labels, y_test_real_pred))\n",
    "print('Discriminator Fake Image Accuracy:', accuracy_score(y_test_fake_labels, y_test_fake_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
